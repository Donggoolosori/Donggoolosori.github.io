---
layout: post
title: "[DLCV] 정밀도(Precision)와 재현율(Recall)"
subtitle: "Deep Learning, Computer Vision"
date: 2020-10-14 16:37:00
author: "dongjune"
header-img: "img/in_post/code-bg.jpg"
catalog: true
tags:
  - Machine Learning
  - Computer Vision
---
![1](https://user-images.githubusercontent.com/53213397/117607354-c435c100-b196-11eb-9a67-b3bab931b710.png)
TN, FP, FN, TP 가 무엇을 의미하는지 처음에는 헷갈린다. 
하지만 **앞이 예측 성공 여부**, **뒤가 예측값**이라는 것을 기억하면 쉽다. 

1. **TN** : Negative로 예측했는데 True이다. (예측 성공)
2. **FP** : Positive로 예측했는데 False이다. (예측 실패)
3. **FN** : Negative로 예측했는데 False이다. (예측 실패)
4. **TP** : Positive로 예측했는데 True이다. (예측 성공)

## 정밀도(Precision)
- 정밀도 =  **TP / ( FP + TP )**
- 정밀도는 내가 Positive로 예측한 값 중에 실제 값이 Positive인 비율이다.
- 아주 확실한 경우에만 positive로 예측할 수록 정밀도는 높아진다.
- 스팸메일과 같이 Negative인 데이터 ( 정상 메일 ) 을 Positive (스팸메일) 로 예측하면 치명적인 경우 중요한 지표이다.

## 재현률(Recall)
- 재현률 = **TP / ( FN + TP )**
- 재현률은 실제 값이 Positive인 대상 중에 내가 Positive로 예측한 비율이다.
- positive로 예측을 많이할수록 재현률은 높아진다. 
- 암 진단, 금융사기 예측과 같이 Positive인 경우 ( 양성, 사기)를 Negative (음성, 정상) 인 경우로 잘못 예측하면 치명적인 경우 중요한 지표이다.

## Object Detection에서의 TP, FP, FN
![2](https://user-images.githubusercontent.com/53213397/117607362-c861de80-b196-11eb-8ef1-67afca16504c.png)
1. TP는 detection에 성공
2. FP는 잘못 예측한 경우. Wrong class, 낮은 IoU 또는 no overlap
3. FN은 물체를 아예 detection 하지 못한 경우

## 정밀도/재현률 Trade Off
![3](https://user-images.githubusercontent.com/53213397/117607368-cb5ccf00-b196-11eb-9261-c08b99790bbb.png)
- 정밀도와 재현률은 상호 보완적 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 한쪽은 수치가 내려가기 쉽다.

## 정밀도 재현률 곡선 ( Precision-Recall Curve)
![4](https://user-images.githubusercontent.com/53213397/117607370-cc8dfc00-b196-11eb-8835-6cd6e3fd9902.png)


- Recall 값의 변화에 따른 Precision 값을 나타낸 곡선
- 이렇게 얻어진 Precision 값의 평균을 AP라고 하며, 일반적으로 **정밀도 재현률 곡선의 면적 값**으로 계산된다.
